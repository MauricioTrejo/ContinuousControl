{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this project we try to move a double-jointed arm to target locations with a reward of +0.1 for each step that the agent's hand is in the goal location.\n",
    "\n",
    "![IMAGE ALT TEXT](reacher.gif)\n",
    "\n",
    "The space consists of 33 variables corresponding to position, rotation, velocity and angular velocities of the arm. Every entry in the action vector should be a number between -1 and 1.\n",
    "\n",
    "The goal of each agent is to keep its position at the target location for as many time steps as possible.\n",
    "\n",
    "There are 2 versions of the environment, the first has 1 agent and the second has 20 agents. To solve the environment in the first version you must reach an average score of +30 while for the second version, the average score of the 20 agents must be +30 over 100 episodes.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Installing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.8 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from agent import Agent\n",
    "\n",
    "from unityagents import UnityEnvironment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved and can be accessed at the file paths provided below.  \n",
    "\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "#env = UnityEnvironment(file_name='/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Obtain information about the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.75471878e+00  -1.00000000e+00\n",
      "   5.55726624e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Behavior of untrained agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.11399999745190144\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # Reset the environment    \n",
    "states = env_info.vector_observations                  # Get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # Initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # Select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # All actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # Send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # Get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # Get reward (for each agent)\n",
    "    dones = env_info.local_done                        # See if episode finished\n",
    "    scores += env_info.rewards                         # Update the score (for each agent)\n",
    "    states = next_states                               # Roll over states to next time step\n",
    "    if np.any(dones):                                  # Exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training the agent\n",
    "\n",
    "The agent and model were based on the one's [here](https://github.com/udacity/deep-reinforcement-learning/tree/master/ddpg-pendulum) with slight changes for it to work with 20 agents.\n",
    "\n",
    "Is important to note that the strategy was to implement an agent that takes 20 different actions which are passed to the environment as the action of 20 agents, those actions are saved one by one in the replay buffer and then sampled when there are enough experiences to learn (we used a threshold of 128 experiences to start learning).\n",
    "\n",
    "##### Hyperparameters\n",
    "\n",
    "To find the best hyperparameters we started to evaluate the behavior of learning with different batch sizes which proved to be an effective way to reach the goal.\n",
    "\n",
    "| Buffer size | Batch size | Gamma |  Tau  | LR Actor | LR Critic | Max Avg Score |\n",
    "|-------------|------------|-------|-------|----------|-----------|---------------|\n",
    "|   10,000    |     128    |  0.99 | 0.001 |  0.0001  |   0.001   |     10.48     |\n",
    "|   10,000    |     256    |  0.99 | 0.001 |  0.0001  |   0.001   |      9.92     |\n",
    "|   10,000    |     512    |  0.99 | 0.001 |  0.0001  |   0.001   |     38.02     |\n",
    "\n",
    "Is interesting to note that doubling the batch size gives worst performance, but quadrupling it results in a quite good performance. \n",
    "\n",
    "After repeating the exercise with a batch size of 512 we found that the learning process can be unstable depending on the initial conditions of the agent.\n",
    "\n",
    "\n",
    "##### Actor model\n",
    "\n",
    "In the case of the actor, we used 2 fully connected hidden layers with 128 and 64 units each and ReLU as activation function except for the output layer where we used a tanh activation function.\n",
    "\n",
    "We had 33 inputs (state size) as input to the network and 4 (action size) as output neurons.\n",
    "\n",
    "##### Critic model\n",
    "\n",
    "For the critic, we used 2 fully connected hidden layers with 132 (128 + number of actions) and 64 units each and ReLU as activation function.\n",
    "\n",
    "We had 33 inputs (state size) as input to the network and 1 neuron (for the Q value estiamtion) as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg(n_episodes = 250, max_t = 1000, print_every = 10):\n",
    "    scores_deque = deque(maxlen=print_every)\n",
    "    scores = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]   # Reset the environment  \n",
    "        states = env_info.vector_observations               # Get the current state\n",
    "        scores_agents = np.zeros(num_agents)\n",
    "        score = 0\n",
    "        agent.reset()\n",
    "        for t in range(max_t):\n",
    "            actions = agent.act(states)                               # Select an action\n",
    "            env_info = env.step(actions)[brain_name]                  # Send the action to tne environment\n",
    "            next_states = env_info.vector_observations                # Get the next state\n",
    "            rewards = env_info.rewards                                # Get the reward    \n",
    "            dones = env_info.local_done                               # See if episode has finished\n",
    "            agent.step(states, actions, rewards, next_states, dones)  # Step and learning process\n",
    "            scores_agents += rewards\n",
    "            states = next_states\n",
    "            if np.any(dones):\n",
    "                break \n",
    "        score = np.mean(scores_agents)\n",
    "        scores_deque.append(score)\n",
    "        scores.append(score)\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)), end=\"\")\n",
    "        torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "        torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 10\tAverage Score: 0.88\n",
      "Episode 20\tAverage Score: 3.08\n",
      "Episode 30\tAverage Score: 8.65\n",
      "Episode 40\tAverage Score: 11.44\n",
      "Episode 50\tAverage Score: 14.66\n",
      "Episode 60\tAverage Score: 18.01\n",
      "Episode 70\tAverage Score: 24.50\n",
      "Episode 80\tAverage Score: 26.73\n",
      "Episode 90\tAverage Score: 27.15\n",
      "Episode 100\tAverage Score: 28.47\n",
      "Episode 110\tAverage Score: 32.46\n",
      "Episode 120\tAverage Score: 34.79\n",
      "Episode 130\tAverage Score: 36.02\n",
      "Episode 140\tAverage Score: 36.37\n",
      "Episode 150\tAverage Score: 36.67\n",
      "Episode 160\tAverage Score: 36.38\n",
      "Episode 170\tAverage Score: 36.44\n",
      "Episode 180\tAverage Score: 36.58\n",
      "Episode 190\tAverage Score: 37.16\n",
      "Episode 200\tAverage Score: 36.71\n",
      "Episode 210\tAverage Score: 36.45\n",
      "Episode 220\tAverage Score: 37.65\n",
      "Episode 230\tAverage Score: 37.69\n",
      "Episode 240\tAverage Score: 38.02\n",
      "Episode 250\tAverage Score: 37.28\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c4c3ffa90>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = Agent(state_size = state_size, action_size = action_size, random_seed = 17)\n",
    "scores = ddpg()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above, we can see that the average score of the agents is above +30 from episode 110 till the end which completes the 100 episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Behavior of trained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 38.42649914110079\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # Reset the environment    \n",
    "states = env_info.vector_observations                  # Get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # Initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = agent.act(states)                        # Select an action (for each agent)\n",
    "    env_info = env.step(actions)[brain_name]           # Send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # Get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # Get reward (for each agent)\n",
    "    dones = env_info.local_done                        # See if episode finished\n",
    "    scores += env_info.rewards                         # Update the score (for each agent)\n",
    "    states = next_states                               # Roll over states to next time step\n",
    "    if np.any(dones):                                  # Exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Ideas for future work\n",
    "\n",
    "1. Use a different architecture for the actor and critic.\n",
    "2. While a deeper network might slow the learning process, it might be possible to maintain it or improve it with a deeper network and more time steps between each round of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
